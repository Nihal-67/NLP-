{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73681767",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Analysis On Movie Review Using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5396bc",
   "metadata": {},
   "source": [
    "In this project we are having 2000 records IMDB movie review database and we will learn sentiment analysis using NLTK directly.\n",
    "Here we used NLTK lexicon called \"VADER\". \n",
    "\n",
    "Note: This text classification only consider the Word and how the word is represent emotion in the sentence i.e. \"Lucky\" and \"Lucky!!!\" have very diffrent score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df445e2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9acc536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"../TextFiles/moviereviews.tsv\", sep='\\t') #loading dataset\n",
    "\n",
    "df.head() #display first 5 records from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bc209",
   "metadata": {},
   "source": [
    "# Remove blank and null records from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "547aa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE NaN VALUES AND EMPTY STRINGS:\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,lb,rv in df.itertuples():  # iterate over the DataFrame\n",
    "    if type(rv)==str:            # avoid NaN values\n",
    "        if rv.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "\n",
    "df.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8e181ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    969\n",
       "pos    969\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts() # TO check total count of label record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641feae8",
   "metadata": {},
   "source": [
    "# Import `SentimentIntensityAnalyzer` and create an sid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd242717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Nihal\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we will download VADER NLTK lexicon which is one time process.\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba931605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad95d6",
   "metadata": {},
   "source": [
    "# Adding Scores and Labels to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4f1c565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...</td>\n",
       "      <td>-0.9125</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "      <td>{'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...</td>\n",
       "      <td>-0.8618</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "      <td>{'neg': 0.068, 'neu': 0.781, 'pos': 0.15, 'com...</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "      <td>{'neg': 0.071, 'neu': 0.782, 'pos': 0.147, 'co...</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "      <td>{'neg': 0.091, 'neu': 0.817, 'pos': 0.093, 'co...</td>\n",
       "      <td>-0.2484</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   neg  how do films like mouse hunt get into theatres...   \n",
       "1   neg  some talented actresses are blessed with a dem...   \n",
       "2   pos  this has been an extraordinary year for austra...   \n",
       "3   pos  according to hollywood movies made in last few...   \n",
       "4   neg  my first press screening of 1998 and already i...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...   -0.9125        neg  \n",
       "1  {'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...   -0.8618        neg  \n",
       "2  {'neg': 0.068, 'neu': 0.781, 'pos': 0.15, 'com...    0.9951        pos  \n",
       "3  {'neg': 0.071, 'neu': 0.782, 'pos': 0.147, 'co...    0.9972        pos  \n",
       "4  {'neg': 0.091, 'neu': 0.817, 'pos': 0.093, 'co...   -0.2484        neg  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review)) \n",
    "#Creates score column with polarity scores that is negative, neutral, postive and compund(Normalize score >=0 represents positive abd <0 represents negative)\n",
    "\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "# Extracting compound score from polarity scores\n",
    "\n",
    "df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "#Converting compound to 'neg' and 'pos' to match with the label\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1f23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e14b3f7",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5acbb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix #Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5904eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357069143446853"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['label'],df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dca25a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.72      0.44      0.55       969\n",
      "         pos       0.60      0.83      0.70       969\n",
      "\n",
      "    accuracy                           0.64      1938\n",
      "   macro avg       0.66      0.64      0.62      1938\n",
      "weighted avg       0.66      0.64      0.62      1938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['label'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cf15df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[427 542]\n",
      " [164 805]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df['label'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcaee1",
   "metadata": {},
   "source": [
    "This complete our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d732815",
   "metadata": {},
   "source": [
    "As we can see VADER is not able to identify very accurately label or sentiment of review. This is the biggeset chanllenges of any sentiment analysis- Understanding the human semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa635615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
